{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Cage Dopamine Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_metadata_dataframe' from 'Hab_Dishab.hd_extension' (/Users/naylajimenez/Documents/GitHub/Fiber_Photometry/Hab_Dishab/hd_extension.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Experiment\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhc_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHab_Dishab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhd_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_trial_dataframes, create_metadata_dataframe, create_da_metrics_dataframe, plot_peak_for_subsequent_investigations_custom\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_metadata_dataframe' from 'Hab_Dishab.hd_extension' (/Users/naylajimenez/Documents/GitHub/Fiber_Photometry/Hab_Dishab/hd_extension.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from trial_class import *\n",
    "from experiment_class import Experiment\n",
    "\n",
    "from hc_extension import *\n",
    "from Hab_Dishab.hd_extension import get_trial_dataframes, create_metadata_dataframe, create_da_metrics_dataframe, plot_peak_for_subsequent_investigations_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_path = r\"C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined\\Home_Cage\\nac\"\n",
    "# csv_base_path = r\"C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined\\Home_Cage\\nac_csvs\"\n",
    "# brain_region = '#15616F'\n",
    "\n",
    "# NAc: #15616F\n",
    "# mPFC: #FFAF00\n",
    "\n",
    "experiment_path = r\"/Users/naylajimenez/Downloads/papers/dopamine/cohort-1-2/allcohorts/C1_2_3_Home_Cage/all/nac\"\n",
    "csv_base_path = r\"//Users/naylajimenez/Downloads/papers/dopamine/cohort-1-2/allcohorts/C1_2_3_Home_Cage/all_csvs/nac_csvs\"\n",
    "brain_region = '#15616F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups csv + experiment data into one variable\n",
    "experiment = Experiment(experiment_path, csv_base_path)\n",
    "\n",
    "# batch process the data, removing the specified time segments for subjects\n",
    "experiment.default_batch_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bout_definitions = [\n",
    "    {'prefix': 'Short_Term', 'introduced': 'Short_Term_Introduced', 'removed': 'Short_Term_Removed'},\n",
    "    {'prefix': 'Long_Term', 'introduced': 'Long_Term_Introduced', 'removed': 'Long_Term_Removed'},\n",
    "    {'prefix': 'Novel', 'introduced': 'Novel_Introduced', 'removed': 'Novel_Removed'}\n",
    "]\n",
    "\n",
    "experiment.group_extract_manual_annotations(bout_definitions, first_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak standard z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_avg_bout_duration = metadata_df[\"Average Bout Duration\"].mean()\n",
    "# print(f\"Total Average Bout Duration: {total_avg_bout_duration:.4f}\")\n",
    "# Proceed with DA metric computation after all files are processed\n",
    "experiment.compute_all_da_metrics(use_max_length=False,\n",
    "                                  max_bout_duration=5, #otal_avg_bout_duration\n",
    "                                  use_adaptive=False, \n",
    "                                  allow_bout_extension=False,\n",
    "                                  mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_da_dict = get_trial_dataframes(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_bouts = ['Short_Term-1', 'Novel-1', 'Short_Term-2', 'Long_Term-1']\n",
    "da_metadata_df = create_da_metrics_dataframe(exp_da_dict, behavior=\"Investigation\", desired_bouts=desired_bouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_da_df = da_metadata_df.copy() \n",
    "\n",
    "# Desired bout order\n",
    "desired_bout_order = [\"Short_Term-1\", \"Short_Term-2\", \"Long_Term-1\", \"Novel-1\"]\n",
    "clean_labels = [\"Acq-ST\", \"Short Term\", \"Long Term\", \"Novel\"]\n",
    "xtick_colors = [\"teal\", \"blue\", \"purple\", \"orange\"]\n",
    "\n",
    "# Map the bout column to a categorical with desired order\n",
    "df = new_da_df[new_da_df[\"Bout\"].isin(desired_bout_order)].copy()\n",
    "df[\"Bout\"] = pd.Categorical(df[\"Bout\"], categories=desired_bout_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dopamine(precomputed_df, \n",
    "             metric_name=\"Mean Z-score\", \n",
    "             title=\"Combined DA Metrics\", \n",
    "             ylabel=\"DA Metric\", \n",
    "             xlabel=\"Bout\", \n",
    "             custom_xtick_labels=None, \n",
    "             custom_xtick_colors=None, \n",
    "             ylim=None, \n",
    "             bar_color=\"#00B7D7\", \n",
    "             yticks_increment=None, \n",
    "             figsize=(14,8), \n",
    "             pad_inches=0.1,\n",
    "             save=False,\n",
    "             save_name=None):\n",
    "    \"\"\"\n",
    "    Plots DA metrics across specific bouts using a provided DataFrame.\n",
    "    Prints paired t-test results comparing first bout to others.\n",
    "    \"\"\"\n",
    "    def perform_t_tests(pivot_df):\n",
    "        results = {}\n",
    "        bout_names = pivot_df.columns.tolist()\n",
    "        for i in range(1, len(bout_names)):\n",
    "            bout1, bout2 = bout_names[0], bout_names[i]\n",
    "            paired_df = pivot_df[[bout1, bout2]].dropna()\n",
    "            if len(paired_df) > 1:\n",
    "                t_stat, p_value = ttest_rel(paired_df[bout1], paired_df[bout2])\n",
    "                significance = \"ns\"\n",
    "                if p_value < 0.001:\n",
    "                    significance = \"***\"\n",
    "                elif p_value < 0.01:\n",
    "                    significance = \"**\"\n",
    "                elif p_value < 0.05:\n",
    "                    significance = \"*\"\n",
    "                results[f\"{bout1} vs {bout2}\"] = {\"t_stat\": t_stat, \"p_value\": p_value, \"significance\": significance}\n",
    "        return results\n",
    "\n",
    "    df = precomputed_df.copy()\n",
    "\n",
    "    try:\n",
    "        pivot_df = df.pivot(index=\"Subject\", columns=\"Bout\", values=metric_name)\n",
    "    except Exception as e:\n",
    "        print(\"Error pivoting data:\", e)\n",
    "        return\n",
    "\n",
    "    overall_stats = df.groupby(\"Bout\")[metric_name].agg(['mean', 'sem']).reset_index()\n",
    "    t_test_results = perform_t_tests(pivot_df)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bar_positions = np.arange(len(overall_stats))\n",
    "\n",
    "    ax.bar(bar_positions, overall_stats[\"mean\"], yerr=overall_stats[\"sem\"],\n",
    "           capsize=6, color=bar_color, edgecolor='black', linewidth=5, width=0.6,\n",
    "           error_kw=dict(elinewidth=3, capthick=3, zorder=5))\n",
    "\n",
    "    for subject_id in pivot_df.index:\n",
    "        ax.plot(bar_positions, pivot_df.loc[subject_id], linestyle='-', color='gray', \n",
    "                alpha=0.5, linewidth=3, marker='o', markerfacecolor='none', \n",
    "                markeredgecolor='gray', markeredgewidth=2, markersize=10)\n",
    "\n",
    "    ax.set_ylabel(ylabel, fontsize=35, labelpad=12)\n",
    "    ax.set_xlabel(xlabel, fontsize=35, labelpad=12)\n",
    "    ax.set_title(title, fontsize=28)\n",
    "\n",
    "    # X-ticks\n",
    "    ax.set_xticks(bar_positions)\n",
    "    xtick_labels = custom_xtick_labels if custom_xtick_labels else overall_stats[\"Bout\"].tolist()\n",
    "    ax.set_xticklabels(xtick_labels, fontsize=28)\n",
    "    if custom_xtick_colors:\n",
    "        for tick, color in zip(ax.get_xticklabels(), custom_xtick_colors):\n",
    "            tick.set_color(color)\n",
    "\n",
    "    ax.tick_params(axis='y', labelsize=35)\n",
    "    ax.tick_params(axis='x', labelsize=35)\n",
    "\n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    else:\n",
    "        all_vals = np.concatenate([pivot_df.values.flatten(), overall_stats[\"mean\"].values])\n",
    "        ax.set_ylim(0, np.nanmax(all_vals) * 1.2)\n",
    "\n",
    "    if yticks_increment:\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        ax.set_yticks(np.arange(np.floor(y_min), np.ceil(y_max) + yticks_increment, yticks_increment))\n",
    "\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(5)\n",
    "    ax.spines['bottom'].set_linewidth(5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if save_name is None:\n",
    "            raise ValueError(\"save_name must be provided if save is True.\")\n",
    "        plt.savefig(save_name, transparent=True, bbox_inches='tight', pad_inches=pad_inches)\n",
    "    plt.show()\n",
    "\n",
    "    # --- Print T-Test Results ---\n",
    "    if t_test_results:\n",
    "        print(\"\\nPaired t-test results (comparing first bout to others):\")\n",
    "        for comparison, stats in t_test_results.items():\n",
    "            print(f\"{comparison}: p = {stats['p_value']:.4f} ({stats['significance']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dopamine(\n",
    "    precomputed_df=df,\n",
    "    metric_name=\"Max Peak\",\n",
    "    title=None,\n",
    "    ylabel=\"Peak Z-scored ∆F/F\",\n",
    "    xlabel=\"Bout Type\",\n",
    "    custom_xtick_labels=clean_labels,\n",
    "    custom_xtick_colors=xtick_colors,\n",
    "    ylim=(-1, 9),\n",
    "    yticks_increment=2,\n",
    "    bar_color=brain_region,\n",
    "    figsize=(14, 8),\n",
    "    save=True,\n",
    "    save_name =\"NAc_C1-3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsequent Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.reset_all_behaviors()\n",
    "experiment.group_extract_manual_annotations(bout_definitions=bout_definitions, first_only = False)\n",
    "\n",
    "# total_avg_bout_duration = metadata_df[\"Average Bout Duration\"].mean()\n",
    "# print(f\"Total Average Bout Duration: {total_avg_bout_duration:.4f}\")\n",
    "# Proceed with DA metric computation after all files are processed\n",
    "experiment.compute_all_da_metrics(use_max_length=False,\n",
    "                                  max_bout_duration=4, #otal_avg_bout_duration\n",
    "                                  use_adaptive=False, \n",
    "                                  allow_bout_extension=False,\n",
    "                                  mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_da_dict = get_trial_dataframes(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def create_big_df_from_exp_da_dict(exp_da_dict):\n",
    "    \"\"\"\n",
    "    Merges all subjects' DataFrames from exp_da_dict into one big DataFrame.\n",
    "    Adds a 'Subject' column for each row.\n",
    "    \"\"\"\n",
    "    all_list = []\n",
    "    for subject_id, df_subj in exp_da_dict.items():\n",
    "        df_copy = df_subj.copy()\n",
    "        df_copy[\"Subject\"] = subject_id\n",
    "        all_list.append(df_copy)\n",
    "    big_df = pd.concat(all_list, ignore_index=True)\n",
    "    return big_df\n",
    "\n",
    "def plot_peak_for_subsequent_investigations_custom(\n",
    "    exp_da_dict,\n",
    "    selected_bouts=None,             # e.g. [\"s1-1\",\"s1-2\"]\n",
    "    n_subsequent_investigations=3,   # e.g. keep first 3 investigations per (Subject, Bout)\n",
    "    peak_col=\"Max Peak\",             # which column holds the per-event peak DA\n",
    "    metric_type='slope',             # choose 'slope' or 'decay'\n",
    "    figsize=(14, 8),\n",
    "    line_order=None,\n",
    "    custom_colors=None,\n",
    "    custom_legend_labels=None,\n",
    "    custom_xtick_labels=None,\n",
    "    ylim=None,\n",
    "    ytick_increment=None,\n",
    "    xlabel=\"Investigation Index\",\n",
    "    ylabel=\"Avg \" + \"Max Peak\",\n",
    "    plot_title=\"Average Peak per Investigation\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Merges all DataFrames in exp_da_dict into one big DataFrame.\n",
    "    2) Filters for the specified bouts (e.g. [\"s1-1\", \"s1-2\"]).\n",
    "    3) Within each (Subject, Bout), sorts by Event_Start and assigns an 'InvestigationIndex'\n",
    "       (1 for the first event, 2 for the second, etc.).\n",
    "    4) Keeps only the first n_subsequent_investigations per (Subject, Bout).\n",
    "    5) Groups by (Bout, InvestigationIndex) across subjects and computes the average of peak_col.\n",
    "    6) For each Bout, fits either a linear regression (if metric_type='slope') or an exponential decay\n",
    "       (if metric_type='decay') to the AvgPeak vs. InvestigationIndex data.\n",
    "       The computed value (slope or decay constant) is shown in the legend.\n",
    "    7) Plots each Bout as a line using full custom visual styling.\n",
    "    \n",
    "    Returns the aggregated DataFrame used for plotting.\n",
    "    \"\"\"\n",
    "\n",
    "    def exponential_decay(x, A, B, tau):\n",
    "        \"\"\"Basic exponential decay model: y = A + B * exp(-x / tau)\"\"\"\n",
    "        return A + B * np.exp(-x / tau)\n",
    "\n",
    "    # 1) Merge all subject data\n",
    "    big_df = create_big_df_from_exp_da_dict(exp_da_dict)\n",
    "    \n",
    "    # 2) Filter for the chosen bouts if provided\n",
    "    if selected_bouts is not None:\n",
    "        big_df = big_df[big_df[\"Bout\"].isin(selected_bouts)].copy()\n",
    "    \n",
    "    if big_df.empty:\n",
    "        print(\"No data left after filtering for bouts. Nothing to plot.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 3) Within each (Subject, Bout), sort by Event_Start and assign an InvestigationIndex\n",
    "    big_df.sort_values([\"Subject\", \"Bout\", \"Event_Start\"], inplace=True)\n",
    "    big_df[\"InvestigationIndex\"] = big_df.groupby([\"Subject\", \"Bout\"]).cumcount() + 1\n",
    "    \n",
    "    # 4) Keep only the first n_subsequent_investigations per (Subject, Bout)\n",
    "    big_df = big_df[big_df[\"InvestigationIndex\"] <= n_subsequent_investigations]\n",
    "    \n",
    "    # 5) Group by (Bout, InvestigationIndex) and compute average peak and subject count\n",
    "    agg_df = (\n",
    "        big_df.groupby([\"Bout\", \"InvestigationIndex\"], as_index=False)\n",
    "        .agg(\n",
    "            SubjectCount=(\"Subject\", \"nunique\"),\n",
    "            AvgPeak=(peak_col, \"mean\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 6) Create figure with custom styling\n",
    "    if custom_colors is None:\n",
    "        custom_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(5)\n",
    "    ax.spines[\"bottom\"].set_linewidth(5)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=48)\n",
    "    \n",
    "    metrics_dict = {}  # to store computed metric for each Bout\n",
    "    \n",
    "    # Determine unique bouts to plot (order by line_order if provided)\n",
    "    if line_order is None:\n",
    "        unique_bouts = sorted(agg_df[\"Bout\"].unique())\n",
    "    else:\n",
    "        unique_bouts = line_order\n",
    "    \n",
    "    # 7) For each Bout, fit the data and plot the line\n",
    "    for i, bout in enumerate(unique_bouts):\n",
    "        df_line = agg_df[agg_df[\"Bout\"] == bout].copy()\n",
    "        df_line.sort_values(\"InvestigationIndex\", inplace=True)\n",
    "        \n",
    "        x_vals = df_line[\"InvestigationIndex\"].values\n",
    "        y_vals = df_line[\"AvgPeak\"].values\n",
    "        \n",
    "        if len(x_vals) == 0 or len(y_vals) == 0:\n",
    "            print(f\"Skipping bout '{bout}' due to no data.\")\n",
    "            continue\n",
    "        \n",
    "        if metric_type.lower() == 'slope':\n",
    "            slope, intercept, r_val, p_val, std_err = linregress(x_vals, y_vals)\n",
    "            metrics_dict[bout] = slope\n",
    "            metric_label = f\"slope: {slope:.3f}\"\n",
    "        elif metric_type.lower() == 'decay':\n",
    "            p0 = (np.min(y_vals), np.max(y_vals)-np.min(y_vals), 1.0)  # initial guess: A, B, tau\n",
    "            try:\n",
    "                popt, _ = curve_fit(exponential_decay, x_vals, y_vals, p0=p0)\n",
    "                tau = popt[2]\n",
    "                metrics_dict[bout] = tau\n",
    "                metric_label = f\"decay: {tau:.3f}\"\n",
    "            except RuntimeError:\n",
    "                metrics_dict[bout] = np.nan\n",
    "                metric_label = \"decay: N/A\"\n",
    "                print(f\"Warning: exponential fit failed for bout '{bout}'.\")\n",
    "        else:\n",
    "            raise ValueError(\"metric_type must be 'slope' or 'decay'.\")\n",
    "        \n",
    "        # Prepare legend text; incorporate custom legend labels if provided\n",
    "        if custom_legend_labels and i < len(custom_legend_labels):\n",
    "            legend_text = custom_legend_labels[i]\n",
    "        else:\n",
    "            legend_text = bout\n",
    "        # Append computed metric and subject count (n) to legend text\n",
    "        legend_text += f\" ({metric_label}, n={df_line['SubjectCount'].max()})\"\n",
    "        \n",
    "        color = custom_colors[i % len(custom_colors)]\n",
    "        ax.plot(\n",
    "            x_vals, y_vals,\n",
    "            marker='o', linestyle='-',\n",
    "            color=color,\n",
    "            linewidth=5, markersize=30,\n",
    "            label=legend_text\n",
    "        )\n",
    "    \n",
    "    # 8) Set axis labels and formatting\n",
    "    ax.set_xlabel(xlabel, fontsize=35, labelpad=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=35, labelpad=12)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "        if ytick_increment is not None:\n",
    "            y_ticks = np.arange(ylim[0], ylim[1] + ytick_increment, ytick_increment)\n",
    "            ax.set_yticks(y_ticks)\n",
    "            y_tick_labels = [f\"{int(yt)}\" if float(yt).is_integer() else f\"{yt:.1f}\" for yt in y_ticks]\n",
    "            ax.set_yticklabels(y_tick_labels, fontsize=44)\n",
    "    \n",
    "    if custom_xtick_labels:\n",
    "        ax.set_xticks(np.arange(1, len(custom_xtick_labels) + 1))\n",
    "        ax.set_xticklabels(custom_xtick_labels, fontsize=44)\n",
    "    else:\n",
    "        unique_x = sorted(agg_df[\"InvestigationIndex\"].unique())\n",
    "        ax.set_xticks(unique_x)\n",
    "        ax.set_xticklabels([str(x) for x in unique_x], fontsize=44)\n",
    "    \n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title, fontsize=20)\n",
    "    \n",
    "    ax.legend(fontsize=26)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"my_plot.png\", transparent=True, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n=== Computed Metric ({metric_type.upper()}): ===\")\n",
    "    for bout, val in metrics_dict.items():\n",
    "        print(f\"Bout: {bout}, {metric_type} = {val:.3f}\")\n",
    "    \n",
    "    return agg_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_da_df = da_metadata_df.copy() \n",
    "\n",
    "# Desired bout order\n",
    "xtick_colors = ['#A839A4','#E06928','#00B7D7','#0045A6'] \n",
    "\n",
    "df_final = plot_peak_for_subsequent_investigations_custom(\n",
    "    exp_da_dict,\n",
    "    selected_bouts=['Short_Term-1', 'Novel-1', 'Short_Term-2', 'Long_Term-1'],\n",
    "    n_subsequent_investigations=5,\n",
    "    custom_colors=xtick_colors,\n",
    "    custom_legend_labels=[\"Long Term\", \"Novel\", \"Acq-ST\", \"Short Term\"],\n",
    "    peak_col=\"Max Peak\",\n",
    "    metric_type='slope', \n",
    "    ylim=(0, 3),\n",
    "    ylabel='Average Peak ∆F/F'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
