# Fiber_Photometry

A modular Python toolkit and set of Jupyter notebooks for analyzing fiber photometry recordings in rodent behavioral neuroscience paradigms.

---

## âœ¨ Overview

This repository implements a flexible pipeline for processing, analyzing, and visualizing fiber photometry data acquired across multiple behavioral contexts (e.g., social defeat, reward training, pinch test). It combines object-oriented Python scripts with notebook-based workflows to enable reproducible and extensible photometry analyses used in the Padilla-Coreano Lab.

---


## âš™ï¸ Requirements

- Python â‰¥ 3.8
- Jupyter Notebook / JupyterLab
  
---


## ğŸš€ Installation

```bash
git clone https://github.com/padillacoreanolab/Fiber_Photometry.git
cd Fiber_Photometry
pip install -r requirements.txt
jupyter notebook
```

---


## ğŸ“ Repository Structure
```
Fiber_Photometry/
â”œâ”€â”€ experiment_class.py â† experiment-level container
â”œâ”€â”€ trial_class.py â† trial-level fiber photometry data handler
â”œâ”€â”€ bouts_extension.py â† methods for extracting and analyzing behavioral bouts
â”‚
â”œâ”€â”€ Social_Defeat/ â† example Jupyter notebooks for the social defeat paradigm
â”œâ”€â”€ Reward_Training-Competition/ â† example notebooks for reward vs competition experiments
â”œâ”€â”€ Hab_Dishab/
â”œâ”€â”€ Home_Cage/
â”œâ”€â”€ Pinch_Test/
â”œâ”€â”€ Social_Pref/
â””â”€â”€ DA_avg_exploration/
```

Each paradigm folder contains example notebooks that instantiate classes from `experiment_class.py` and `trial_class.py`, load data, perform preprocessing (downsampling, detrending, Î”F/F or Z-score computation), and generate analysis plots (PSTH, heatmaps, etc).

---

## ğŸ“‚ Data Organization and File Structure

All raw photometry recordings are collected using **TDT Synapse**, which automatically saves each session as its own **block folder** (TDT tank structure). Each experiment therefore consists of multiple block folders, one per recording.

### 1. âœ… TDT Block Structure

A typical experiment folder looks like:
```
<Experiment_Root>/
â”œâ”€â”€ n6-240821-100116/ â† TDT block
â”‚ â”œâ”€â”€ Streams/ # raw DA (465 nm) & ISOS (405 nm) fiber photometry channels
â”‚ â”œâ”€â”€ Info/
â”‚ â”œâ”€â”€ TimeEvents/ # TTLs or task events recorded during acquisition
â”‚ â””â”€â”€ ...
â”œâ”€â”€ n7-240821-114717/
â”œâ”€â”€ nn1-250115-052028/
â”œâ”€â”€ nn2-250115-054951/
â””â”€â”€ ...
```

- Folder names follow: `<animalID>-<YYMMDD>-<time>` (as generated by **Synapse**).
- Each folder contains *binary* TDT files which are parsed using our `experiment_class.py` and `trial_class.py`.

---

### 2. ğŸ­ Behavior-Linked Experiments (e.g., Hab/Dishab, Social Defeat)

Some paradigms include extra behavioral annotations collected outside of Synapse â€” commonly using **BORIS** or **Ethovision**, exported as `.csv`.  
To link behavior to photometry traces, the CSV filename **must match** the corresponding TDT block folder.

Example:
```
Hab_Dishab/
â”œâ”€â”€ All/
â”‚ â”œâ”€â”€ nac/ # Block folders for NAc recordings
â”‚ â”‚ â”œâ”€â”€ n6-240821-100116/
â”‚ â”‚ â”œâ”€â”€ n7-240821-114717/
â”‚ â”‚ â””â”€â”€ ...
â”‚ â””â”€â”€ nac_csvs/ # Behavioral CSVs
â”‚ â”œâ”€â”€ n6-240821-100116.csv
â”‚ â”œâ”€â”€ n7-240821-114717.csv
â”‚ â””â”€â”€ ...
```

**Convention:**
- **`<region>/`** â†’ Raw photometry blocks
- **`<region>_csvs/`** â†’ Matching behavior file for each block

During preprocessing, the `Experiment` class automatically looks in `*_csvs/` for a file with the same name and loads the behavioral timestamps to align with the photometry signal. This enables event-locked PSTHs and bout analyses.

---

## ğŸ“Œ Summary of Required Inputs per Recording

| Field             | Source     | File Type         | Required? |
|------------------|-----------|--------------------|-----------|
| Photometry Signal| TDT Synapse | Block Folder       | âœ…        |
| TTL Events       | Synapse     | Stored inside block | âœ… (for event-driven experiments) |
| Behavioral Events| BORIS/others| .csv (matching filename) | âœ… for HabDishab, Social Defeat etc. |
| Region Tracking  | Folder Name | nch (`nac/`, `mpfc/`, etc.) | âœ… needed to route to correct analysis pipeline |

---

## ğŸ“¥ Adding a New Dataset

To analyze a new set of recordings with this repository:

1. Place all *TDT block folders* in a directory named after the brain region (e.g., `nac/`).
2. (If applicable) export your behavioral annotations as `.csv` and put them in a subfolder named `<region>_csvs/`.
3. Make sure **the CSV filename exactly matches the block folder name**.
4. Create a bout definitions dictionary identifying bouts and what they are called in Boris csvs.
5. Point the experiment class to the experiment root:

```python
from experiment_class import Experiment

exp = Experiment(
    experiment_path=".../Hab_Dishab/All",
    region="nac"
)
exp.default_batch_process()
exp.group_extract_manual_annotations(bout_definitions=bout_definitions, first_only = True)
exp.compute_all_da_metrics(use_max_length=False,
                                  max_bout_duration=4, 
                                  mode='standard')      





