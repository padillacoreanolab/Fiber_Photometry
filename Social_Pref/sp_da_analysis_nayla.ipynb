{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from trial_class import *\n",
    "from experiment_class import Experiment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tdt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sp_extension import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = r\"C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\"\n",
    "csv_base_path = r\"C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac_csvs\"\n",
    "\n",
    "# NAc: #15616F\n",
    "# mPFC: #FFAF00\n",
    "\n",
    "cups = r\"C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\Social_Pref_sheet.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n1-240522-072114\\Notes.txt\n",
      "read from t=0s to t=794.67s\n",
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n2-240522-084131\\Notes.txt\n",
      "read from t=0s to t=789.95s\n",
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n3-240523-073132\\Notes.txt\n",
      "read from t=0s to t=788.57s\n",
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n4-240523-084829\\Notes.txt\n",
      "read from t=0s to t=790.88s\n",
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n5-240826-083822\\Notes.txt\n",
      "read from t=0s to t=793.05s\n",
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n6-240826-094701\\Notes.txt\n",
      "read from t=0s to t=800.05s\n",
      "Found Synapse note file: C:\\Users\\alber\\OneDrive\\Desktop\\PC_Lab\\Photometry\\Pilot_2\\Combined_Cohorts\\Social_Pref\\nac\\n7-240827-072608\\Notes.txt\n",
      "read from t=0s to t=795.64s\n",
      "Processing n1-240522-072114...\n",
      "Processing n2-240522-084131...\n",
      "Processing n3-240523-073132...\n",
      "Processing n4-240523-084829...\n",
      "Processing n5-240826-083822...\n",
      "Processing n6-240826-094701...\n",
      "Processing n7-240827-072608...\n"
     ]
    }
   ],
   "source": [
    "# groups csv + experiment data into one variable\n",
    "experiment = Experiment(experiment_path, csv_base_path)\n",
    "\n",
    "# batch process the data, removing the specified time segments for subjects\n",
    "experiment.default_batch_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing behaviors for n1-240522-072114...\n",
      "Processing behaviors for n2-240522-084131...\n",
      "Processing behaviors for n3-240523-073132...\n",
      "Processing behaviors for n4-240523-084829...\n",
      "Processing behaviors for n5-240826-083822...\n",
      "Processing behaviors for n6-240826-094701...\n",
      "Processing behaviors for n7-240827-072608...\n"
     ]
    }
   ],
   "source": [
    "bout_definitions = [\n",
    "    {'prefix': 'Subject', 'introduced': 'Subject Introduced', 'removed': 'Subject Removed'},\n",
    "]\n",
    "\n",
    "\n",
    "experiment.group_extract_manual_annotations(bout_definitions,first_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dopamine Stuff (Need help with this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_combined_da_metrics(experiment, sniff_cup_csv_path, metric_list=None, first_only=False):\n",
    "    import pandas as pd\n",
    "    import re\n",
    "\n",
    "    # Normalize behavior label spacing\n",
    "    def normalize_behavior_label(label):\n",
    "        return re.sub(r'\\s+', ' ', label.strip().lower().replace('\\u00a0', ' '))\n",
    "\n",
    "    assign_df = pd.read_csv(sniff_cup_csv_path)\n",
    "    assign_df['Subject'] = assign_df['Subject'].astype(str).str.lower()\n",
    "\n",
    "    # Build subject -> behavior name -> agent identity mapping\n",
    "    subject_to_behavior_to_agent = {}\n",
    "    for _, row in assign_df.iterrows():\n",
    "        subj = row['Subject']\n",
    "        subject_to_behavior_to_agent[subj] = {}\n",
    "        for col in row.index:\n",
    "            col_norm = normalize_behavior_label(str(col))\n",
    "            if col_norm.startswith(\"sniff cup\"):\n",
    "                agent_label = normalize_behavior_label(str(row[col]))\n",
    "                subject_to_behavior_to_agent[subj][col_norm] = agent_label\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for trial_name, trial in experiment.trials.items():\n",
    "        if not hasattr(trial, 'behaviors') or trial.behaviors.empty:\n",
    "            continue\n",
    "\n",
    "        df = trial.behaviors.copy()\n",
    "        df['Behavior'] = df['Behavior'].astype(str).apply(normalize_behavior_label)\n",
    "\n",
    "        subject_id = trial_name.lower()\n",
    "\n",
    "        if subject_id not in subject_to_behavior_to_agent:\n",
    "            continue\n",
    "\n",
    "        mapping = subject_to_behavior_to_agent[subject_id]\n",
    "\n",
    "        # Keep only sniff cup behaviors\n",
    "        df = df[df[\"Behavior\"].str.startswith(\"sniff cup\")]\n",
    "\n",
    "        # Map behaviors to agents\n",
    "        df[\"Agent\"] = df[\"Behavior\"].apply(lambda b: mapping.get(b))\n",
    "        df[\"Subject\"] = subject_id\n",
    "        df[\"Trial\"] = trial_name\n",
    "\n",
    "        unmatched = df[df[\"Agent\"].isna()]\n",
    "        if not unmatched.empty:\n",
    "            print(f\"‼️ Unmatched behaviors for subject '{subject_id}':\")\n",
    "            print(\"Behaviors that failed to map:\", unmatched[\"Behavior\"].unique())\n",
    "            print(\"Available mapping keys:\", list(mapping.keys()))\n",
    "\n",
    "        df = df.dropna(subset=[\"Agent\"])\n",
    "\n",
    "        # Choose metrics\n",
    "        known_cols = [\"Behavior\", \"Agent\", \"Subject\", \"Trial\"]\n",
    "        if metric_list:\n",
    "            metric_cols = [m for m in metric_list if m in df.columns]\n",
    "        else:\n",
    "            metric_cols = [c for c in df.columns if c not in known_cols and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "        if not metric_cols:\n",
    "            continue\n",
    "\n",
    "        df = df[[\"Subject\", \"Agent\"] + metric_cols]\n",
    "\n",
    "        if first_only:\n",
    "            df = df.groupby([\"Subject\", \"Agent\"], as_index=False).first()\n",
    "\n",
    "        all_rows.append(df)\n",
    "\n",
    "    if not all_rows:\n",
    "        print(\"⚠️ No rows added to DataFrame. Check if behavior labels match and mapping keys are clean.\")\n",
    "        print(f\"Subjects in experiment: {list(experiment.trials.keys())}\")\n",
    "        print(f\"Subjects in assignments file: {assign_df['Subject'].tolist()}\")\n",
    "        print(\"Sample mapping dictionary:\")\n",
    "        for subj, mapping in subject_to_behavior_to_agent.items():\n",
    "            print(f\"{subj} -> {mapping}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    combined_df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # --- Aggregate by Subject-Agent pair ---\n",
    "    if first_only:\n",
    "        grouped = combined_df  # already one row per subject-agent\n",
    "    else:\n",
    "        grouped = combined_df.groupby([\"Subject\", \"Agent\"], as_index=False)[metric_cols].mean()\n",
    "\n",
    "    # --- Ensure each subject has all 4 agent rows ---\n",
    "    all_agents = ['nothing', 'short_term', 'long_term', 'novel']\n",
    "    all_subjects = sorted(grouped['Subject'].unique())\n",
    "    full_index = pd.MultiIndex.from_product([all_subjects, all_agents], names=['Subject', 'Agent'])\n",
    "\n",
    "    final_df = (\n",
    "        grouped.set_index(['Subject', 'Agent'])\n",
    "               .reindex(full_index)\n",
    "               .fillna(0)\n",
    "               .reset_index()\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Final DA metrics DataFrame created with {len(final_df)} rows from {len(all_subjects)} subjects.\")\n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DA metrics for n1-240522-072114 ...\n",
      "Computing DA metrics for n2-240522-084131 ...\n",
      "Computing DA metrics for n3-240523-073132 ...\n",
      "Computing DA metrics for n4-240523-084829 ...\n",
      "Computing DA metrics for n5-240826-083822 ...\n",
      "Computing DA metrics for n6-240826-094701 ...\n",
      "Computing DA metrics for n7-240827-072608 ...\n"
     ]
    }
   ],
   "source": [
    "experiment.compute_all_da_metrics(use_max_length=False,\n",
    "                                  max_bout_duration=5, #total_avg_bout_duration\n",
    "                                  mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<experiment_class.Experiment at 0x1cce31656a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No rows added to DataFrame. Check if behavior labels match and mapping keys are clean.\n",
      "Subjects in experiment: ['n1-240522-072114', 'n2-240522-084131', 'n3-240523-073132', 'n4-240523-084829', 'n5-240826-083822', 'n6-240826-094701', 'n7-240827-072608']\n",
      "Subjects in assignments file: ['n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
      "Sample mapping dictionary:\n",
      "n1 -> {}\n",
      "n2 -> {}\n",
      "n3 -> {}\n",
      "n4 -> {}\n",
      "n5 -> {}\n",
      "n6 -> {}\n",
      "n7 -> {}\n",
      "p1 -> {}\n",
      "p2 -> {}\n",
      "p3 -> {}\n",
      "p4 -> {}\n",
      "p5 -> {}\n",
      "p6 -> {}\n",
      "p7 -> {}\n",
      "p8 -> {}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build the combined dataframe, aggregating by mean across trials\n",
    "combined_df = prep_combined_da_metrics(\n",
    "    experiment=experiment,\n",
    "    sniff_cup_csv_path=cups,\n",
    "    metric_list=[\"Max Peak\", \"Mean Z-score\", \"AUC\"],\n",
    "    first_only=True\n",
    ")\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nac_pref_list = ['n5-240826-083822']\n",
    "mpfc_pref_list =['p5-240826-091418', 'pp3-250118-064713', 'p7-240826-102402', 'p4-240523-092600']\n",
    "\n",
    "nac_no_pref_list = ['nn2-250117-085631', 'nn4-250118-094351', 'n6-240826-094701', 'nn1-250117-081652', 'nn8-250118-105443', 'nn7-250118-101917', 'pp8-250118-083250', 'nn6-250117-101903', 'n7-240827-072608', 'nn3-250118-090940', 'nn5-250117-093631']\n",
    "mpfc_no_pref_list =['p2-240523-081105','pp7-250118-075659', 'p8-240827-075823', 'p1-240522-080200', 'p6-240827-065303', 'pp5-250117-121543', 'pp4-250118-072201', 'pp6-250117-124823', 'p3-240522-092431','pp1-250117-110456', 'pp2-250117-113909']\n",
    "\n",
    "nac_list=['nn2-250117-085631', 'nn4-250118-094351', 'n6-240826-094701', 'nn1-250117-081652', 'nn8-250118-105443', 'nn7-250118-101917', 'pp8-250118-083250', 'nn6-250117-101903', 'n7-240827-072608', 'nn3-250118-090940', 'nn5-250117-093631', 'n5-240826-083822']\n",
    "mpfc_list=['p5-240826-091418', 'pp3-250118-064713', 'p7-240826-102402', 'p4-240523-092600','p2-240523-081105','pp7-250118-075659', 'p8-240827-075823', 'p1-240522-080200', 'p6-240827-065303', 'pp5-250117-121543', 'pp4-250118-072201', 'pp6-250117-124823', 'p3-240522-092431','pp1-250117-110456', 'pp2-250117-113909']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data to plot after filtering.\n",
      "⚠️ No data to plot after filtering.\n",
      "⚠️ No data to plot after filtering.\n",
      "⚠️ No data to plot after filtering.\n"
     ]
    }
   ],
   "source": [
    "def dopamine(precomputed_df, \n",
    "             metric_name=\"Mean Z-score\", \n",
    "             title=\"Combined DA Metrics\", \n",
    "             ylabel=\"DA Metric\", \n",
    "             xlabel=\"Agent\", \n",
    "             custom_xtick_labels=None, \n",
    "             custom_xtick_colors=None, \n",
    "             ylim=None, \n",
    "             bar_color=\"#00B7D7\", \n",
    "             yticks_increment=None, \n",
    "             figsize=(14, 8), \n",
    "             pad_inches=0.1,\n",
    "             save=False,\n",
    "             save_name=None,\n",
    "             subjects_to_include=None,\n",
    "             highlight_subject=None):\n",
    "    \"\"\"\n",
    "    Plots DA metrics across agents (\"nothing\", \"short_term\", \"long_term\", \"novel\")\n",
    "    with subject-level spaghetti plots and paired t-tests.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import ttest_rel\n",
    "\n",
    "    fixed_order = [\"nothing\", \"short_term\", \"long_term\", \"novel\"]\n",
    "    bar_positions = np.arange(len(fixed_order))\n",
    "\n",
    "    def perform_all_pairwise_t_tests(pivot_df):\n",
    "        results = {}\n",
    "        bout_names = pivot_df.columns.tolist()\n",
    "        for i in range(len(bout_names)):\n",
    "            for j in range(i + 1, len(bout_names)):\n",
    "                bout1, bout2 = bout_names[i], bout_names[j]\n",
    "                paired_df = pivot_df[[bout1, bout2]].dropna()\n",
    "                if len(paired_df) > 1:\n",
    "                    t_stat, p_value = ttest_rel(paired_df[bout1], paired_df[bout2])\n",
    "                    results[f\"{bout1} vs {bout2}\"] = {\"t_stat\": t_stat, \"p_value\": p_value}\n",
    "        return results\n",
    "\n",
    "    df = precomputed_df.copy()\n",
    "\n",
    "    # --- Filter by Subject ---\n",
    "    if subjects_to_include is not None:\n",
    "        subjects_to_include = [s.lower() for s in subjects_to_include]\n",
    "        df['Subject'] = df['Subject'].astype(str).str.lower()\n",
    "        df = df[df['Subject'].isin(subjects_to_include)]\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"⚠️ No data to plot after filtering.\")\n",
    "        return\n",
    "\n",
    "    # --- Pivot by Subject x Agent ---\n",
    "    try:\n",
    "        pivot_df = df.pivot(index=\"Subject\", columns=\"Agent\", values=metric_name)\n",
    "    except Exception as e:\n",
    "        print(\"Error pivoting data:\", e)\n",
    "        return\n",
    "\n",
    "    pivot_df = pivot_df.reindex(columns=fixed_order)\n",
    "\n",
    "    # --- Summary Stats ---\n",
    "    stats = pivot_df.agg(['mean', 'sem']).T.reset_index()\n",
    "    stats.columns = ['Agent', 'mean', 'sem']\n",
    "    stats = stats.set_index('Agent').reindex(fixed_order).reset_index()\n",
    "\n",
    "    means = stats['mean'].values\n",
    "    sems = stats['sem'].values\n",
    "\n",
    "    # --- Paired T-tests ---\n",
    "    t_test_results = perform_all_pairwise_t_tests(pivot_df)\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Bars\n",
    "    ax.bar(\n",
    "        bar_positions,\n",
    "        means,\n",
    "        yerr=sems,\n",
    "        capsize=10,\n",
    "        color=bar_color,\n",
    "        edgecolor='black',\n",
    "        linewidth=5,\n",
    "        width=0.6\n",
    "    )\n",
    "\n",
    "    # Spaghetti lines (gray for all, black for highlight)\n",
    "    for subject_id, row in pivot_df.iterrows():\n",
    "        if highlight_subject and subject_id.lower() == highlight_subject.lower():\n",
    "            ax.plot(bar_positions, row.values, linestyle='-', color='black', linewidth=4, zorder=3)\n",
    "            ax.scatter(bar_positions, row.values, facecolors='black', edgecolors='black', \n",
    "                       s=160, linewidths=2, zorder=4)\n",
    "        else:\n",
    "            ax.plot(bar_positions, row.values, linestyle='-', color='gray', alpha=0.5, linewidth=2.5, zorder=1)\n",
    "            ax.scatter(bar_positions, row.values, facecolors='none', edgecolors='gray', \n",
    "                       s=120, linewidths=3, zorder=2)\n",
    "\n",
    "    # Labels\n",
    "    ax.set_ylabel(ylabel, fontsize=35, labelpad=12)\n",
    "    ax.set_xlabel(xlabel, fontsize=35, labelpad=12)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=28)\n",
    "\n",
    "    ax.set_xticks(bar_positions)\n",
    "    xtick_labels = custom_xtick_labels if custom_xtick_labels else [\"Empty\", \"Short Term\", \"Long Term\", \"Novel\"]\n",
    "    ax.set_xticklabels(xtick_labels, fontsize=35)\n",
    "    if custom_xtick_colors:\n",
    "        for tick, color in zip(ax.get_xticklabels(), custom_xtick_colors):\n",
    "            tick.set_color(color)\n",
    "\n",
    "    ax.tick_params(axis='y', labelsize=35)\n",
    "    ax.tick_params(axis='x', labelsize=35)\n",
    "\n",
    "    # Y-limits\n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    else:\n",
    "        all_vals = np.concatenate([pivot_df.values.flatten(), means])\n",
    "        ax.set_ylim(0, np.nanmax(all_vals) * 1.2)\n",
    "\n",
    "    if yticks_increment:\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        ax.set_yticks(np.arange(np.floor(y_min), np.ceil(y_max) + yticks_increment, yticks_increment))\n",
    "\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(5)\n",
    "    ax.spines['bottom'].set_linewidth(5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if save_name is None:\n",
    "            raise ValueError(\"save_name must be provided if save is True.\")\n",
    "        plt.savefig(save_name, transparent=True, bbox_inches='tight', pad_inches=pad_inches)\n",
    "    plt.show()\n",
    "\n",
    "    # --- Print T-tests ---\n",
    "    print(f\"\\nPlotted data from {pivot_df.shape[0]} subject(s).\")\n",
    "    if t_test_results:\n",
    "        print(\"\\nPaired t-test results (all agent comparisons):\")\n",
    "        for comp, stats in t_test_results.items():\n",
    "            p = stats[\"p_value\"]\n",
    "            stars = \"ns\"\n",
    "            if p < 0.001:\n",
    "                stars = \"***\"\n",
    "            elif p < 0.01:\n",
    "                stars = \"**\"\n",
    "            elif p < 0.05:\n",
    "                stars = \"*\"\n",
    "            print(f\"{comp}: p = {p:.4f} ({stars})\")\n",
    "\n",
    "labels=[\"Empty\", \"Short Term\", \"Long Term\", \"Novel\"]\n",
    "colors=[\"black\", \"blue\", \"purple\", \"orange\"]\n",
    "\n",
    "dopamine(\n",
    "    precomputed_df=combined_df,\n",
    "    metric_name=\"Max Peak\",\n",
    "    ylabel=\"Standard Peak ∆F/F\",\n",
    "    xlabel=\"Agent\",\n",
    "    custom_xtick_labels=labels,\n",
    "    custom_xtick_colors=colors,\n",
    "    bar_color=\"#FFAF00\",\n",
    "    ylim=(-2, 4),\n",
    "    yticks_increment=2,\n",
    "    figsize=(14, 8),\n",
    "    save=True,\n",
    "    save_name =\"mpfc_pref_DA\",\n",
    "    title=None\n",
    ")\n",
    "dopamine(\n",
    "    precomputed_df=combined_df,\n",
    "    metric_name=\"Max Peak\",\n",
    "    ylabel=\"Standard Peak ∆F/F\",\n",
    "    xlabel=\"Agent\",\n",
    "    custom_xtick_labels=labels,\n",
    "    custom_xtick_colors=colors,\n",
    "    bar_color=\"#FFAF00\",\n",
    "    ylim=(-2, 4),\n",
    "    yticks_increment=2,\n",
    "    figsize=(14, 8),\n",
    "    save=True,\n",
    "    save_name =\"mpfc_no_pref_DA\",\n",
    "    title=None\n",
    ")\n",
    "\n",
    "dopamine(\n",
    "    precomputed_df=combined_df,\n",
    "    metric_name=\"Max Peak\",\n",
    "    ylabel=\"Standard Peak ∆F/F\",\n",
    "    xlabel=\"Agent\",\n",
    "    custom_xtick_labels=labels,\n",
    "    custom_xtick_colors=colors,\n",
    "    bar_color=\"#15616F\",\n",
    "    ylim=(-2, 10),\n",
    "    yticks_increment=2,\n",
    "    figsize=(14, 8),\n",
    "    save=True,\n",
    "    save_name =\"nac_pref_DA\",\n",
    "    title=None\n",
    ")\n",
    "\n",
    "dopamine(\n",
    "    precomputed_df=combined_df,\n",
    "    metric_name=\"Max Peak\",\n",
    "    ylabel=\"Standard Peak ∆F/F\",\n",
    "    xlabel=\"Agent\",\n",
    "    custom_xtick_labels=labels,\n",
    "    custom_xtick_colors=colors,\n",
    "    bar_color=\"#15616F\",\n",
    "    ylim=(-2, 10),\n",
    "    yticks_increment=2,\n",
    "    figsize=(14, 8),\n",
    "    save=True,\n",
    "    save_name =\"nac_no_pref_DA\",\n",
    "    title=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DA across subsequent bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing behaviors for n1-240522-072114...\n",
      "Processing behaviors for n2-240522-084131...\n",
      "Processing behaviors for n3-240523-073132...\n",
      "Processing behaviors for n4-240523-084829...\n",
      "Processing behaviors for n5-240826-083822...\n",
      "Processing behaviors for n6-240826-094701...\n",
      "Processing behaviors for n7-240827-072608...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Experiment.compute_all_da_metrics() got an unexpected keyword argument 'use_adaptive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m experiment\u001b[38;5;241m.\u001b[39mreset_all_behaviors()\n\u001b[0;32m      3\u001b[0m experiment\u001b[38;5;241m.\u001b[39mgroup_extract_manual_annotations(bout_definitions\u001b[38;5;241m=\u001b[39mbout_definitions, first_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_all_da_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_max_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_bout_duration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_adaptive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_bout_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstandard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Experiment.compute_all_da_metrics() got an unexpected keyword argument 'use_adaptive'"
     ]
    }
   ],
   "source": [
    "# 1. Re-extract all behaviors and re-calculate DA metrics\n",
    "experiment.reset_all_behaviors()\n",
    "experiment.group_extract_manual_annotations(bout_definitions=bout_definitions, first_only=False)\n",
    "\n",
    "experiment.compute_all_da_metrics(\n",
    "    use_max_length=False,\n",
    "    max_bout_duration=4,\n",
    "    use_adaptive=False,\n",
    "    allow_bout_extension=False,\n",
    "    mode='standard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_per_event_df(experiment, sniff_cup_csv_path, metric_list=None):\n",
    "    import re\n",
    "\n",
    "    def normalize_label(label):\n",
    "        return re.sub(r'\\s+', ' ', str(label).strip().lower().replace('\\u00a0', ' '))\n",
    "\n",
    "    # Load mapping from cup -> agent\n",
    "    assign_df = pd.read_csv(sniff_cup_csv_path)\n",
    "    assign_df['Subject'] = assign_df['Subject'].str.lower()\n",
    "    \n",
    "    subj_map = {}\n",
    "    for _, row in assign_df.iterrows():\n",
    "        subj = row['Subject']\n",
    "        subj_map[subj] = {}\n",
    "        for col in row.index:\n",
    "            col_norm = normalize_label(col)\n",
    "            if col_norm.startswith(\"sniff cup\"):\n",
    "                agent = normalize_label(row[col])\n",
    "                subj_map[subj][col_norm] = agent\n",
    "\n",
    "    all_rows = []\n",
    "    for trial_name, trial in experiment.trials.items():\n",
    "        if not hasattr(trial, 'behaviors') or trial.behaviors.empty:\n",
    "            continue\n",
    "\n",
    "        df = trial.behaviors.copy()\n",
    "        df['Behavior'] = df['Behavior'].astype(str).apply(normalize_label)\n",
    "\n",
    "        subject_id = trial_name.lower()\n",
    "        if subject_id not in subj_map:\n",
    "            continue\n",
    "\n",
    "        df = df[df['Behavior'].str.startswith(\"sniff cup\")]\n",
    "        df['Agent'] = df['Behavior'].apply(lambda b: subj_map[subject_id].get(b))\n",
    "        df['Subject'] = subject_id\n",
    "        df['Trial'] = trial_name\n",
    "\n",
    "        df = df.dropna(subset=[\"Agent\"])\n",
    "        \n",
    "        known = ['Subject', 'Agent', 'Trial', 'Behavior', 'Event_Start']\n",
    "        if metric_list:\n",
    "            cols = [col for col in metric_list if col in df.columns]\n",
    "        else:\n",
    "            cols = [c for c in df.columns if c not in known and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "        df = df[['Subject', 'Agent', 'Trial', 'Event_Start'] + cols]\n",
    "        all_rows.append(df)\n",
    "\n",
    "    final_df = pd.concat(all_rows, ignore_index=True)\n",
    "    print(f\"✅ Per-event DataFrame created with {len(final_df)} rows from {final_df['Subject'].nunique()} subjects.\")\n",
    "    return final_df\n",
    "\n",
    "per_event_df = get_all_per_event_df(experiment, sniff_cup_csv_path=cups, metric_list=[\"Max Peak\", \"Mean Z-score\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peak_by_agent_from_df(\n",
    "    df,\n",
    "    sniff_cup_csv_path=None,              # optional if Agent column is already present\n",
    "    selected_agents=None,                # e.g. ['novel', 'short_term']\n",
    "    n_subsequent_investigations=3,\n",
    "    peak_col=\"Max Peak\",\n",
    "    metric_type='slope',\n",
    "    figsize=(14, 8),\n",
    "    line_order=None,\n",
    "    custom_colors=None,\n",
    "    custom_legend_labels=None,\n",
    "    custom_xtick_labels=None,\n",
    "    ylim=None,\n",
    "    ytick_increment=None,\n",
    "    xlabel=\"Investigation Index\",\n",
    "    ylabel=\"Avg Max Peak\",\n",
    "    subjects_to_include=None,            # ✅ MISSING COMMA FIXED HERE\n",
    "    plot_title=\"Average Peak per Agent\",\n",
    "    save=False,\n",
    "    save_name=\"agent_peak_plot.png\"\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import linregress\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    def exponential_decay(x, A, B, tau):\n",
    "        return A + B * np.exp(-x / tau)\n",
    "\n",
    "    def normalize_label(label):\n",
    "        import re\n",
    "        return re.sub(r'\\s+', ' ', str(label).strip().lower().replace('\\u00a0', ' '))\n",
    "\n",
    "    def create_mapping(sniff_cup_csv_path):\n",
    "        assign_df = pd.read_csv(sniff_cup_csv_path)\n",
    "        assign_df['Subject'] = assign_df['Subject'].astype(str).str.lower()\n",
    "        subject_to_behavior_to_agent = {}\n",
    "        for _, row in assign_df.iterrows():\n",
    "            subj = row['Subject']\n",
    "            subject_to_behavior_to_agent[subj] = {}\n",
    "            for col in row.index:\n",
    "                col_norm = normalize_label(col)\n",
    "                if col_norm.startswith(\"sniff cup\"):\n",
    "                    agent_label = normalize_label(row[col])\n",
    "                    subject_to_behavior_to_agent[subj][col_norm] = agent_label\n",
    "        return subject_to_behavior_to_agent\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Optional agent mapping ---\n",
    "    if \"Agent\" not in df.columns:\n",
    "        if sniff_cup_csv_path is None:\n",
    "            raise ValueError(\"You must provide either an 'Agent' column or a sniff_cup_csv_path.\")\n",
    "\n",
    "        mapping = create_mapping(sniff_cup_csv_path)\n",
    "\n",
    "        def get_agent(row):\n",
    "            subj = str(row['Subject']).lower()\n",
    "            bout = str(row['Bout']).lower()\n",
    "            if '-' not in bout:\n",
    "                return None\n",
    "            cup_number = bout.split('-')[1]\n",
    "            behavior = f\"sniff cup {cup_number}\"\n",
    "            return mapping.get(subj, {}).get(behavior)\n",
    "\n",
    "        df['Agent'] = df.apply(get_agent, axis=1)\n",
    "\n",
    "    # --- Filter agents ---\n",
    "    if selected_agents:\n",
    "        df = df[df['Agent'].isin(selected_agents)]\n",
    "\n",
    "    # --- Subject filtering ---\n",
    "    if subjects_to_include:\n",
    "        subjects_to_include = [s.lower() for s in subjects_to_include]\n",
    "        df['Subject'] = df['Subject'].astype(str).str.lower()\n",
    "        df = df[df['Subject'].isin(subjects_to_include)]\n",
    "\n",
    "    # --- Investigation indexing ---\n",
    "    df.sort_values([\"Subject\", \"Agent\", \"Event_Start\"], inplace=True)\n",
    "    df[\"InvestigationIndex\"] = df.groupby([\"Subject\", \"Agent\"]).cumcount() + 1\n",
    "    df = df[df[\"InvestigationIndex\"] <= n_subsequent_investigations]\n",
    "\n",
    "    # --- Aggregate ---\n",
    "    agg_df = (\n",
    "        df.groupby([\"Agent\", \"InvestigationIndex\"], as_index=False)\n",
    "        .agg(\n",
    "            SubjectCount=(\"Subject\", \"nunique\"),\n",
    "            AvgPeak=(peak_col, \"mean\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Plotting ---\n",
    "    if custom_colors is None:\n",
    "        custom_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(5)\n",
    "    ax.spines[\"bottom\"].set_linewidth(5)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=48)\n",
    "    ax.tick_params(axis=\"y\", labelsize=35)\n",
    "\n",
    "    metrics_dict = {}\n",
    "    unique_agents = line_order if line_order else sorted(agg_df[\"Agent\"].dropna().unique())\n",
    "\n",
    "    for i, agent in enumerate(unique_agents):\n",
    "        df_line = agg_df[agg_df[\"Agent\"] == agent].copy()\n",
    "        df_line.sort_values(\"InvestigationIndex\", inplace=True)\n",
    "\n",
    "        x_vals = df_line[\"InvestigationIndex\"].values\n",
    "        y_vals = df_line[\"AvgPeak\"].values\n",
    "\n",
    "        if len(x_vals) == 0 or len(y_vals) == 0:\n",
    "            print(f\"Skipping agent '{agent}' due to no data.\")\n",
    "            continue\n",
    "\n",
    "        if metric_type.lower() == 'slope':\n",
    "            slope, _, _, _, _ = linregress(x_vals, y_vals)\n",
    "            metrics_dict[agent] = slope\n",
    "            metric_label = f\"slope: {slope:.3f}\"\n",
    "        elif metric_type.lower() == 'decay':\n",
    "            try:\n",
    "                p0 = (np.min(y_vals), np.max(y_vals)-np.min(y_vals), 1.0)\n",
    "                popt, _ = curve_fit(exponential_decay, x_vals, y_vals, p0=p0)\n",
    "                tau = popt[2]\n",
    "                metrics_dict[agent] = tau\n",
    "                metric_label = f\"decay: {tau:.3f}\"\n",
    "            except RuntimeError:\n",
    "                metrics_dict[agent] = np.nan\n",
    "                metric_label = \"decay: N/A\"\n",
    "        else:\n",
    "            raise ValueError(\"metric_type must be 'slope' or 'decay'.\")\n",
    "\n",
    "        legend_label = custom_legend_labels[i] if custom_legend_labels and i < len(custom_legend_labels) else agent\n",
    "        legend_label += f\" ({metric_label}, n={df_line['SubjectCount'].max()})\"\n",
    "\n",
    "        color = custom_colors[i % len(custom_colors)]\n",
    "        ax.plot(\n",
    "            x_vals, y_vals,\n",
    "            marker='o', linestyle='-',\n",
    "            color=color,\n",
    "            linewidth=5, markersize=30,\n",
    "            label=legend_label\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=35, labelpad=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=35, labelpad=12)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "        if ytick_increment is not None:\n",
    "            ticks = np.arange(ylim[0], ylim[1] + ytick_increment, ytick_increment)\n",
    "            ax.set_yticks(ticks)\n",
    "            ax.set_yticklabels([f\"{t:.0f}\" if t.is_integer() else f\"{t:.1f}\" for t in ticks], fontsize=35)\n",
    "\n",
    "    if custom_xtick_labels:\n",
    "        ax.set_xticks(np.arange(1, len(custom_xtick_labels) + 1))\n",
    "        ax.set_xticklabels(custom_xtick_labels, fontsize=35)\n",
    "    else:\n",
    "        x_vals = sorted(agg_df[\"InvestigationIndex\"].unique())\n",
    "        ax.set_xticks(x_vals)\n",
    "        ax.set_xticklabels([str(x) for x in x_vals], fontsize=35)\n",
    "\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title, fontsize=24)\n",
    "\n",
    "    ax.legend(fontsize=26)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save_name, dpi=300, transparent=True, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n=== Computed Metric ({metric_type.upper()}): ===\")\n",
    "    for agent, val in metrics_dict.items():\n",
    "        print(f\"Agent: {agent}, {metric_type} = {val:.3f}\")\n",
    "\n",
    "    return agg_df\n",
    "\n",
    "lines = ['nothing','short_term','long_term','novel']\n",
    "\n",
    "plot_peak_by_agent_from_df(\n",
    "    df=per_event_df,\n",
    "    selected_agents=lines,\n",
    "    peak_col=\"Max Peak\",\n",
    "    metric_type=\"slope\",  # or \"slope\"\n",
    "    custom_colors = ['black','#0045A6','#A839A4','#E06928'],\n",
    "    custom_legend_labels=['Empty', 'Short Term', 'Long Term', 'Novel'],\n",
    "    line_order=lines,\n",
    "    n_subsequent_investigations=5,\n",
    "    ylim=(-1, 4),\n",
    "    ytick_increment=2,\n",
    "    ylabel = 'Average Peak ΔF/F',\n",
    "    subjects_to_include=mpfc_pref_list,\n",
    "    plot_title=None,\n",
    "    save=False,\n",
    "    save_name=\"\"\n",
    ")\n",
    "\n",
    "plot_peak_by_agent_from_df(\n",
    "    df=per_event_df,\n",
    "    selected_agents=lines,\n",
    "    peak_col=\"Max Peak\",\n",
    "    metric_type=\"slope\",  # or \"slope\"\n",
    "    custom_colors = ['black','#0045A6','#A839A4','#E06928'],\n",
    "    custom_legend_labels=['Empty', 'Short Term', 'Long Term', 'Novel'],\n",
    "    line_order=lines,\n",
    "    n_subsequent_investigations=5,\n",
    "    ylim=(-1, 3),\n",
    "    ytick_increment=1,\n",
    "    ylabel = 'Average Peak ΔF/F',\n",
    "    subjects_to_include=mpfc_no_pref_list,\n",
    "    plot_title=None,\n",
    "    save=False,\n",
    "    save_name=\"\"\n",
    ")\n",
    "\n",
    "plot_peak_by_agent_from_df(\n",
    "    df=per_event_df,\n",
    "    selected_agents=lines,\n",
    "    peak_col=\"Max Peak\",\n",
    "    metric_type=\"slope\",  # or \"slope\"\n",
    "    custom_colors = ['black','#0045A6','#A839A4','#E06928'],\n",
    "    custom_legend_labels=['Empty', 'Short Term', 'Long Term', 'Novel'],\n",
    "    line_order=lines,\n",
    "    n_subsequent_investigations=5,\n",
    "    ylim=(-4, 10),\n",
    "    ytick_increment=2,\n",
    "    ylabel = 'Average Peak ΔF/F',\n",
    "    subjects_to_include=nac_pref_list,\n",
    "    plot_title=None,\n",
    "    save=False,\n",
    "    save_name=\"\"\n",
    ")\n",
    "\n",
    "plot_peak_by_agent_from_df(\n",
    "    df=per_event_df,\n",
    "    selected_agents=lines,\n",
    "    peak_col=\"Max Peak\",\n",
    "    metric_type=\"slope\",  # or \"slope\"\n",
    "    custom_colors = ['black','#0045A6','#A839A4','#E06928'],\n",
    "    custom_legend_labels=['Empty', 'Short Term', 'Long Term', 'Novel'],\n",
    "    line_order=lines,\n",
    "    n_subsequent_investigations=5,\n",
    "    ylim=(-0.5, 3.5),\n",
    "    ytick_increment=1,\n",
    "    ylabel = 'Average Peak ΔF/F',\n",
    "    subjects_to_include=nac_no_pref_list,\n",
    "    plot_title=None,\n",
    "    save=False,\n",
    "    save_name=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DA vs % TIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Re-extract all behaviors and re-calculate DA metrics\n",
    "experiment.reset_all_behaviors()\n",
    "experiment.group_extract_manual_annotations(bout_definitions=bout_definitions, first_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cups = \"/Users/naylajimenez/Downloads/papers/dopamine/cohort-1-2/allcohorts/Social_Pref_Cup_Assignments.csv\"\n",
    "\n",
    "# Correct data input\n",
    "trial_data_with_ids = get_trial_dataframes_with_ids(experiment)\n",
    "\n",
    "# Create metadata with mapping\n",
    "metadata_df = create_metadata_dataframe_with_agent_mapping(trial_data_with_ids, sniff_cup_csv_path=cups)\n",
    "\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_da_vs_percent_investigation_time_by_agent(\n",
    "    dopamine_df,\n",
    "    metadata_df,\n",
    "    agents_of_interest,\n",
    "    agent_colors,\n",
    "    agent_labels,\n",
    "    da_metric='Max Peak',\n",
    "    use_first_only=True,\n",
    "    subjects_to_include=None,\n",
    "    title=\"DA vs % Investigation Time\",\n",
    "    ylabel=None,\n",
    "    figsize=(10, 7),\n",
    "    ylim=None,\n",
    "    yticks_increment=None,\n",
    "    legend_loc='upper left',\n",
    "    pad_inches=0.1,\n",
    "    save=False,\n",
    "    save_name=None\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as ticker\n",
    "    from scipy.stats import linregress\n",
    "\n",
    "    # --- Prep subject IDs ---\n",
    "    if \"Subject\" not in metadata_df.columns:\n",
    "        metadata_df = metadata_df.reset_index()\n",
    "    metadata_df[\"Subject\"] = metadata_df[\"Subject\"].astype(str).str.lower()\n",
    "    dopamine_df[\"Subject\"] = dopamine_df[\"Subject\"].astype(str).str.lower()\n",
    "\n",
    "    if subjects_to_include:\n",
    "        subjects_to_include = [s.lower() for s in subjects_to_include]\n",
    "        metadata_df = metadata_df[metadata_df[\"Subject\"].isin(subjects_to_include)]\n",
    "        dopamine_df = dopamine_df[dopamine_df[\"Subject\"].isin(subjects_to_include)]\n",
    "\n",
    "    # --- Corrected: Calculate percent investigation time for selected agents ---\n",
    "    percent_records = []\n",
    "\n",
    "    # Get all agent names from metadata by parsing columns like \"Total_novel\"\n",
    "    all_agent_names = [\n",
    "        col.replace(\"Total_\", \"\") for col in metadata_df.columns if col.startswith(\"Total_\")\n",
    "    ]\n",
    "\n",
    "    for _, row in metadata_df.iterrows():\n",
    "        subj = row[\"Subject\"]\n",
    "\n",
    "        # Total investigation time across all agents (not just selected ones)\n",
    "        total_all = sum([\n",
    "            row.get(f\"Total_{agent}\", 0)\n",
    "            for agent in all_agent_names\n",
    "        ])\n",
    "\n",
    "        if total_all == 0:\n",
    "            continue  # skip subject if no total investigation time at all\n",
    "\n",
    "        for agent in agents_of_interest:\n",
    "            agent_time = row.get(f\"Total_{agent}\", 0)\n",
    "            percent = agent_time / total_all\n",
    "\n",
    "            percent_records.append({\n",
    "                \"Subject\": subj,\n",
    "                \"Agent\": agent,\n",
    "                \"PercentTime\": percent\n",
    "            })\n",
    "\n",
    "    percent_df = pd.DataFrame(percent_records)\n",
    "\n",
    "\n",
    "    # --- Prepare DA values ---\n",
    "    if use_first_only:\n",
    "        dopamine_df = dopamine_df.groupby([\"Subject\", \"Agent\"], as_index=False).first()\n",
    "    else:\n",
    "        dopamine_df = dopamine_df.groupby([\"Subject\", \"Agent\"], as_index=False)[da_metric].mean()\n",
    "\n",
    "    # --- Merge time + DA ---\n",
    "    merged_df = pd.merge(dopamine_df, percent_df, on=[\"Subject\", \"Agent\"], how=\"inner\")\n",
    "\n",
    "    if merged_df.empty:\n",
    "        print(\"⚠️ No data to plot after merging.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['bottom'].set_linewidth(3)\n",
    "\n",
    "    all_x, all_y = [], []\n",
    "\n",
    "    for agent in agents_of_interest:\n",
    "        sub = merged_df[merged_df[\"Agent\"] == agent]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[\"PercentTime\"].values * 100\n",
    "        y = sub[da_metric].values\n",
    "\n",
    "        all_x.extend(x)\n",
    "        all_y.extend(y)\n",
    "\n",
    "        color = agent_colors.get(agent, 'gray')\n",
    "        label = agent_labels.get(agent, agent)\n",
    "\n",
    "        ax.scatter(x, y, color=color, s=250, alpha=1.0, edgecolor='black', linewidth=3, label=label, zorder=3)\n",
    "\n",
    "    # --- Regression line ---\n",
    "    stats_text_lines = [\"r = ---\", \"p = ---\", \"n = ---\"]\n",
    "    if len(set(all_x)) > 1:  # ← Fix: only do regression if x-values aren't all identical\n",
    "        slope, intercept, r_val, p_val, _ = linregress(all_x, all_y)\n",
    "        x_fit = np.linspace(min(all_x), max(all_x), 100)\n",
    "        y_fit = slope * x_fit + intercept\n",
    "        ax.plot(x_fit, y_fit, color='black', linewidth=2.5, linestyle='-', zorder=2)\n",
    "\n",
    "        stats_text_lines = [\n",
    "            f\"r = {r_val:.3f}\",\n",
    "            f\"p = {p_val:.3f}\",\n",
    "            f\"n = {len(all_x)} points\"\n",
    "        ]\n",
    "\n",
    "    ax.set_xlabel(\"% Investigation Time\", fontsize=24)\n",
    "    ax.set_ylabel(ylabel if ylabel else da_metric, fontsize=24)\n",
    "    ax.set_title(title, fontsize=26)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    if yticks_increment:\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        yticks = np.arange(np.floor(y_min), np.ceil(y_max) + yticks_increment, yticks_increment)\n",
    "        ax.set_yticks(yticks)\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{int(x)}'))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{int(x)}' if x.is_integer() else f'{x:.1f}'))\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    stats_handle = plt.Line2D([], [], color='none', label=\"\\n\".join(stats_text_lines))\n",
    "    handles.append(stats_handle)\n",
    "    labels.append(\"\\n\".join(stats_text_lines))\n",
    "\n",
    "    legend = ax.legend(handles=handles, labels=labels, loc=legend_loc, fontsize=16, title='Agent', title_fontsize=18,\n",
    "                       frameon=True, facecolor='white', edgecolor='lightgray', fancybox=False)\n",
    "    legend.get_frame().set_alpha(0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if save_name is None:\n",
    "            raise ValueError(\"save_name must be provided if save is True.\")\n",
    "        plt.savefig(save_name, transparent=True, bbox_inches='tight', pad_inches=pad_inches)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "plot_da_vs_percent_investigation_time_by_agent(\n",
    "    dopamine_df=combined_df,  # your DA dataframe with 'Subject', 'Agent', DA metrics\n",
    "    metadata_df=metadata_df,  # from your time analysis notebook\n",
    "    agents_of_interest=[\"nothing\"],\n",
    "    agent_colors={\"nothing\": \"black\"},\n",
    "    agent_labels={\"novel\": \"Novel\", \"short_term\": \"Short Term\", \"long_term\": \"Long Term\", \"nothing\": \"Empty\"},\n",
    "    da_metric=\"Max Peak\",\n",
    "    use_first_only=True,\n",
    "    title=\"NAc Nothing\",\n",
    "    ylabel=\"Peak Z-scored ∆F/F\", \n",
    "    subjects_to_include=nac_list,\n",
    "    legend_loc='upper right',\n",
    "    save=False,\n",
    "    save_name=\"da_vs_invest_time_corr.png\"\n",
    ")\n",
    "\n",
    "plot_da_vs_percent_investigation_time_by_agent(\n",
    "    dopamine_df=combined_df,  # your DA dataframe with 'Subject', 'Agent', DA metrics\n",
    "    metadata_df=metadata_df,  # from your time analysis notebook\n",
    "    agents_of_interest=[\"novel\"],\n",
    "    agent_colors={\"novel\": \"#E06928\"},\n",
    "    agent_labels={\"novel\": \"Novel\"},\n",
    "    da_metric=\"Max Peak\",\n",
    "    use_first_only=True,\n",
    "    title=\"NAc Novel\",\n",
    "    ylabel=\"Peak Z-scored ∆F/F\", \n",
    "    subjects_to_include=nac_list,\n",
    "    legend_loc='upper right',\n",
    "    save=False,\n",
    "    save_name=\"da_vs_invest_time_corr.png\"\n",
    ")\n",
    "\n",
    "plot_da_vs_percent_investigation_time_by_agent(\n",
    "    dopamine_df=combined_df,  # your DA dataframe with 'Subject', 'Agent', DA metrics\n",
    "    metadata_df=metadata_df,  # from your time analysis notebook\n",
    "    agents_of_interest=[\"short_term\"],\n",
    "    agent_colors={\"short_term\": \"#0045A6\"},\n",
    "    agent_labels={\"short_term\": \"Short Term\",},\n",
    "    da_metric=\"Max Peak\",\n",
    "    use_first_only=True,\n",
    "    title=\"NAc Short Term\",\n",
    "    ylabel=\"Peak Z-scored ∆F/F\", \n",
    "    subjects_to_include=nac_list,\n",
    "    legend_loc='upper right',\n",
    "    save=False,\n",
    "    save_name=\"da_vs_invest_time_corr.png\"\n",
    ")\n",
    "\n",
    "plot_da_vs_percent_investigation_time_by_agent(\n",
    "    dopamine_df=combined_df,  # your DA dataframe with 'Subject', 'Agent', DA metrics\n",
    "    metadata_df=metadata_df,  # from your time analysis notebook\n",
    "    agents_of_interest=[\"long_term\"],\n",
    "    agent_colors={\"long_term\": \"#A839A4\"},\n",
    "    agent_labels={\"long_term\": \"Long Term\"},\n",
    "    da_metric=\"Max Peak\",\n",
    "    use_first_only=True,\n",
    "    title=\"NAc Long Term\",\n",
    "    ylabel=\"Peak Z-scored ∆F/F\", \n",
    "    subjects_to_include=nac_list,\n",
    "    legend_loc='lower right',\n",
    "    save=False,\n",
    "    save_name=\"da_vs_invest_time_corr.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = [\n",
    "    \"Behavior\", \"Bout\", \"Event_Start\", \"Event_End\", \"Duration (s)\", \"AUC\",\n",
    "    \"Max Peak\", \"Time of Max Peak\", \"Mean Z-score\", \"Adjusted End\",\n",
    "    \"Relative_Time_Axis\", \"Relative_Zscore\"\n",
    "]\n",
    "\n",
    "for trial in experiment.trials.values():\n",
    "    if hasattr(trial, \"behaviors\") and not trial.behaviors.empty:\n",
    "        df = trial.behaviors.copy()\n",
    "        df.columns = raw_columns\n",
    "\n",
    "        # Force all rows to be labeled as 'Investigation' for behavior\n",
    "        df[\"Behavior\"] = \"Investigation\"\n",
    "        trial.behaviors = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_da_dict = get_trial_dataframes(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Bout</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Max Peak</th>\n",
       "      <th>Mean Z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 1</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 2</td>\n",
       "      <td>investigation</td>\n",
       "      <td>-11.359314</td>\n",
       "      <td>1.420445</td>\n",
       "      <td>-1.622571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 3</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 4</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nn2</td>\n",
       "      <td>sniff cup 1</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>pp1</td>\n",
       "      <td>sniff cup 4</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 1</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 2</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 3</td>\n",
       "      <td>investigation</td>\n",
       "      <td>4.075799</td>\n",
       "      <td>1.629273</td>\n",
       "      <td>0.463285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 4</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject         Bout       Behavior        AUC  Max Peak  Mean Z-score\n",
       "0       p5  sniff cup 1  investigation   0.000000  0.000000      0.000000\n",
       "1       p5  sniff cup 2  investigation -11.359314  1.420445     -1.622571\n",
       "2       p5  sniff cup 3  investigation   0.000000  0.000000      0.000000\n",
       "3       p5  sniff cup 4  investigation   0.000000  0.000000      0.000000\n",
       "4      nn2  sniff cup 1  investigation   0.000000  0.000000      0.000000\n",
       "..     ...          ...            ...        ...       ...           ...\n",
       "87     pp1  sniff cup 4  investigation   0.000000  0.000000      0.000000\n",
       "88     pp2  sniff cup 1  investigation   0.000000  0.000000      0.000000\n",
       "89     pp2  sniff cup 2  investigation   0.000000  0.000000      0.000000\n",
       "90     pp2  sniff cup 3  investigation   4.075799  1.629273      0.463285\n",
       "91     pp2  sniff cup 4  investigation   0.000000  0.000000      0.000000\n",
       "\n",
       "[92 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_bouts = ['sniff cup 1', 'sniff cup 2', 'sniff cup 3', 'sniff cup 4']\n",
    "da_metadata_df = create_da_metrics_dataframe(\n",
    "    exp_da_dict,\n",
    "    behavior=\"Investigation\",\n",
    "    desired_bouts=desired_bouts\n",
    ")\n",
    "\n",
    "da_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Bout</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Max Peak</th>\n",
       "      <th>Mean Z-score</th>\n",
       "      <th>Agent_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 1</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 2</td>\n",
       "      <td>investigation</td>\n",
       "      <td>-11.359314</td>\n",
       "      <td>1.420445</td>\n",
       "      <td>-1.622571</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 3</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>short_term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p5</td>\n",
       "      <td>sniff cup 4</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>long_term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nn2</td>\n",
       "      <td>sniff cup 1</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>long_term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>pp1</td>\n",
       "      <td>sniff cup 4</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>long_term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 1</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>long_term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 2</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 3</td>\n",
       "      <td>investigation</td>\n",
       "      <td>4.075799</td>\n",
       "      <td>1.629273</td>\n",
       "      <td>0.463285</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>pp2</td>\n",
       "      <td>sniff cup 4</td>\n",
       "      <td>investigation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>short_term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject         Bout       Behavior        AUC  Max Peak  Mean Z-score  \\\n",
       "0       p5  sniff cup 1  investigation   0.000000  0.000000      0.000000   \n",
       "1       p5  sniff cup 2  investigation -11.359314  1.420445     -1.622571   \n",
       "2       p5  sniff cup 3  investigation   0.000000  0.000000      0.000000   \n",
       "3       p5  sniff cup 4  investigation   0.000000  0.000000      0.000000   \n",
       "4      nn2  sniff cup 1  investigation   0.000000  0.000000      0.000000   \n",
       "..     ...          ...            ...        ...       ...           ...   \n",
       "87     pp1  sniff cup 4  investigation   0.000000  0.000000      0.000000   \n",
       "88     pp2  sniff cup 1  investigation   0.000000  0.000000      0.000000   \n",
       "89     pp2  sniff cup 2  investigation   0.000000  0.000000      0.000000   \n",
       "90     pp2  sniff cup 3  investigation   4.075799  1.629273      0.463285   \n",
       "91     pp2  sniff cup 4  investigation   0.000000  0.000000      0.000000   \n",
       "\n",
       "    Agent_Type  \n",
       "0      nothing  \n",
       "1        novel  \n",
       "2   short_term  \n",
       "3    long_term  \n",
       "4    long_term  \n",
       "..         ...  \n",
       "87   long_term  \n",
       "88   long_term  \n",
       "89     nothing  \n",
       "90       novel  \n",
       "91  short_term  \n",
       "\n",
       "[92 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_sniff_cups_to_agents(da_df, cup_assignments_csv_path):\n",
    "    \"\"\"\n",
    "    Maps sniff cup labels (e.g., 'sniff cup 1') to agent types \n",
    "    using subject-specific assignments from a CSV.\n",
    "    \"\"\"\n",
    "    # Load and normalize the assignment CSV\n",
    "    cup_df = pd.read_csv(cup_assignments_csv_path)\n",
    "    cup_df[\"Subject\"] = cup_df[\"Subject\"].str.strip().str.lower()\n",
    "\n",
    "    # Extract subject prefix (e.g., 'p5' from 'p5-240826-091418')\n",
    "    cup_df[\"Subject_Prefix\"] = cup_df[\"Subject\"].str.split(\"-\").str[0]\n",
    "\n",
    "    # Melt long format\n",
    "    mapping_long = cup_df.melt(\n",
    "        id_vars=[\"Subject\", \"Subject_Prefix\"],\n",
    "        var_name=\"Cup_Label\",\n",
    "        value_name=\"Agent_Type\"\n",
    "    )\n",
    "    mapping_long[\"Cup_Label\"] = mapping_long[\"Cup_Label\"].str.strip().str.lower()\n",
    "    mapping_long[\"Agent_Type\"] = mapping_long[\"Agent_Type\"].str.strip().str.lower()\n",
    "\n",
    "    # Normalize da_df\n",
    "    da_df = da_df.copy()\n",
    "    da_df[\"Subject_clean\"] = da_df[\"Subject\"].str.strip().str.lower()\n",
    "    da_df[\"Bout_clean\"] = da_df[\"Bout\"].str.strip().str.lower()\n",
    "\n",
    "    # Merge by prefix + cup label\n",
    "    merged_df = da_df.merge(\n",
    "        mapping_long,\n",
    "        left_on=[\"Subject_clean\", \"Bout_clean\"],\n",
    "        right_on=[\"Subject_Prefix\", \"Cup_Label\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Clean up\n",
    "    merged_df.drop(columns=[\"Subject_clean\", \"Bout_clean\", \"Cup_Label\", \"Subject_Prefix\", \"Subject_y\"], inplace=True)\n",
    "    merged_df.rename(columns={\"Subject_x\": \"Subject\"}, inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "cups = \"/Users/naylajimenez/Downloads/papers/dopamine/cohort-1-2/allcohorts/Cup_Assignments.csv\"\n",
    "da_with_agents_df = map_sniff_cups_to_agents(da_metadata_df, cups)\n",
    "da_with_agents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data remaining after subject filtering.\n"
     ]
    }
   ],
   "source": [
    "Pref = ['p5-240826-091418', 'pp3-250118-064713', 'pp5-250117-121543', 'pp4-250118-072201', 'p7-240826-102402', 'nn3-250118-090940', 'p4-240523-092600']\n",
    "No_Pref = ['nn2-250117-085631', 'p2-240523-081105', 'nn4-250118-094351', 'nn1-250117-081652', 'pp7-250118-075659', 'p8-240827-075823', 'nn8-250118-105443', 'p1-240522-080200', 'p6-240827-065303', 'nn7-250118-101917', 'pp8-250118-083250', 'nn6-250117-101903', 'pp6-250117-124823', 'p3-240522-092431', 'nn5-250117-093631', 'pp1-250117-110456', 'pp2-250117-113909']\n",
    "\n",
    "def plot_da_by_agent_type(precomputed_df, \n",
    "             metric_name=\"Mean Z-score\", \n",
    "             title=\"DA Metrics by Agent Type\", \n",
    "             ylabel=\"DA Metric\", \n",
    "             xlabel=\"Agent Type\", \n",
    "             custom_xtick_labels=None, \n",
    "             custom_xtick_colors=None, \n",
    "             ylim=None, \n",
    "             bar_color=\"#00B7D7\", \n",
    "             yticks_increment=None, \n",
    "             figsize=(14,8), \n",
    "             pad_inches=0.1,\n",
    "             save=False,\n",
    "             save_name=None,\n",
    "             subjects_to_include=None,\n",
    "             agent_order=None):  # ✅ New param\n",
    "    \"\"\"\n",
    "    Plots DA metrics across agent types using a provided DataFrame.\n",
    "    Supports subject filtering and manual agent ordering.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.stats import ttest_rel\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def perform_t_tests(pivot_df):\n",
    "        results = {}\n",
    "        agent_types = pivot_df.columns.tolist()\n",
    "        for i in range(1, len(agent_types)):\n",
    "            agent1, agent2 = agent_types[0], agent_types[i]\n",
    "            paired_df = pivot_df[[agent1, agent2]].dropna()\n",
    "            if len(paired_df) > 1:\n",
    "                t_stat, p_value = ttest_rel(paired_df[agent1], paired_df[agent2])\n",
    "                significance = \"ns\"\n",
    "                if p_value < 0.001:\n",
    "                    significance = \"***\"\n",
    "                elif p_value < 0.01:\n",
    "                    significance = \"**\"\n",
    "                elif p_value < 0.05:\n",
    "                    significance = \"*\"\n",
    "                results[f\"{agent1} vs {agent2}\"] = {\n",
    "                    \"t_stat\": t_stat, \n",
    "                    \"p_value\": p_value, \n",
    "                    \"significance\": significance\n",
    "                }\n",
    "        return results\n",
    "\n",
    "    df = precomputed_df.copy()\n",
    "\n",
    "    # ✅ Filter by subject ID\n",
    "    if subjects_to_include is not None:\n",
    "        df = df[df[\"Subject\"].isin(subjects_to_include)]\n",
    "        if df.empty:\n",
    "            print(\"No data remaining after subject filtering.\")\n",
    "            return\n",
    "\n",
    "    # ✅ Group and sort mean/SEM values by agent\n",
    "    overall_stats = df.groupby(\"Agent_Type\")[metric_name].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "    if agent_order:\n",
    "        # enforce the agent order\n",
    "        overall_stats[\"Agent_Type\"] = pd.Categorical(overall_stats[\"Agent_Type\"], categories=agent_order, ordered=True)\n",
    "        overall_stats = overall_stats.sort_values(\"Agent_Type\")\n",
    "\n",
    "    # ✅ Pivot per subject for line overlays\n",
    "    try:\n",
    "        pivot_df = df.pivot(index=\"Subject\", columns=\"Agent_Type\", values=metric_name)\n",
    "        if agent_order:\n",
    "            pivot_df = pivot_df[agent_order]  # reorder columns\n",
    "    except Exception as e:\n",
    "        print(\"Error pivoting data:\", e)\n",
    "        return\n",
    "\n",
    "    # ✅ Paired t-tests\n",
    "    t_test_results = perform_t_tests(pivot_df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bar_positions = np.arange(len(overall_stats))\n",
    "\n",
    "    ax.bar(bar_positions, overall_stats[\"mean\"], yerr=overall_stats[\"sem\"],\n",
    "           capsize=6, color=bar_color, edgecolor='black', linewidth=5, width=0.6,\n",
    "           error_kw=dict(elinewidth=3, capthick=3, zorder=5))\n",
    "\n",
    "    for subject_id in pivot_df.index:\n",
    "        ax.plot(bar_positions, pivot_df.loc[subject_id], linestyle='-', color='gray', \n",
    "                alpha=0.5, linewidth=3, marker='o', markerfacecolor='none', \n",
    "                markeredgecolor='gray', markeredgewidth=2, markersize=10)\n",
    "\n",
    "    ax.set_ylabel(ylabel, fontsize=35, labelpad=12)\n",
    "    ax.set_xlabel(xlabel, fontsize=35, labelpad=12)\n",
    "    ax.set_title(title, fontsize=28)\n",
    "\n",
    "    ax.set_xticks(bar_positions)\n",
    "    xtick_labels = custom_xtick_labels if custom_xtick_labels else overall_stats[\"Agent_Type\"].tolist()\n",
    "    ax.set_xticklabels(xtick_labels, fontsize=28)\n",
    "    if custom_xtick_colors:\n",
    "        for tick, color in zip(ax.get_xticklabels(), custom_xtick_colors):\n",
    "            tick.set_color(color)\n",
    "\n",
    "    ax.tick_params(axis='y', labelsize=35)\n",
    "    ax.tick_params(axis='x', labelsize=35)\n",
    "\n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    else:\n",
    "        all_vals = np.concatenate([pivot_df.values.flatten(), overall_stats[\"mean\"].values])\n",
    "        ax.set_ylim(0, np.nanmax(all_vals) * 1.2)\n",
    "\n",
    "    if yticks_increment:\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        ax.set_yticks(np.arange(np.floor(y_min), np.ceil(y_max) + yticks_increment, yticks_increment))\n",
    "\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(5)\n",
    "    ax.spines['bottom'].set_linewidth(5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if save_name is None:\n",
    "            raise ValueError(\"save_name must be provided if save is True.\")\n",
    "        plt.savefig(save_name, transparent=True, bbox_inches='tight', pad_inches=pad_inches)\n",
    "    plt.show()\n",
    "\n",
    "    if t_test_results:\n",
    "        print(\"\\nPaired t-test results (comparing first agent type to others):\")\n",
    "        for comparison, stats in t_test_results.items():\n",
    "            print(f\"{comparison}: p = {stats['p_value']:.4f} ({stats['significance']})\")\n",
    "\n",
    "\n",
    "plot_da_by_agent_type(\n",
    "    precomputed_df=da_with_agents_df,\n",
    "    metric_name=\"Max Peak\",\n",
    "    title=None,\n",
    "    ylabel=\"Peak Z-scored ∆F/F\",\n",
    "    xlabel=\"Bout Type\",\n",
    "    agent_order=[\"nothing\", \"short_term\", \"long_term\", \"novel\"],\n",
    "    subjects_to_include= Pref,\n",
    "    custom_xtick_labels=[\"Empty\", \"Short Term\", \"Long Term\", \"Novel\"],\n",
    "    custom_xtick_colors=None,\n",
    "    ylim=(-1, 3),\n",
    "    yticks_increment=2,\n",
    "    bar_color='white',\n",
    "    figsize=(14, 8),\n",
    "    save=None,\n",
    "    save_name =\"mPFC_C1_3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
